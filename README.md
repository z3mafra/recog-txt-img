# Azura, Vision Studio: Detect faces; Read text; e, Analyze images
## Entrega do projeto: Reposit√≥rio: recog-txt-img

Desafio:

1. Criar um novo reposit√≥rio no github com um nome a sua prefer√™ncia;  
2. Criar uma pasta chamada 'inputs' e salve as imagens que voc√™ utilizou;  
3. Criar uma pasta chamado 'output' e salve os resultados de reconhecimento de texto nessas imagens;  
4. Criar um arquivo chamado readme.md, deixe alguns prints descreva o processo, alguns insights e possibilidades que voc√™ aprendeu durante o conte√∫do;  
5. Compartilhar conosco o link desse reposit√≥rio atrav√©s do bot√£o 'entregar projeto'.  
  
-------

## 1. Criar um novo reposit√≥rio no github com um nome a sua prefer√™ncia  

Na maquina local foi crido o diret√≥rio 'recog-txt-ing'  

~~~bash
$ mkdir regog-txt-img
~~~  

Depois, iniciei o diret√≥rio como um reposit√≥rio no Git.

~~~bash
$ git init
~~~

No GitHub foi criado o reposit√≥rio recog-txt-img

> Comandos/configura√ß√µes:  
> 
> - "Novo reposit√≥rio".  
> - Nome para o reposit√≥rio: "recog-txt-img".  
> - Descri√ß√£o: "Projeto Vision Studio com tr√™s processos de identifica√ß√£o: Detect faces; Read text; e, Analyze images.".  
> - Visibilidade: "p√∫blica".  
> - Op√ß√£o: LEIAME.  
> - Cliquei em "Criar reposit√≥rio".  
> 

-------

## 2. Criar uma pasta chamada 'inputs' e salve as imagens que voc√™ utilizou  

Na maquina local, na raiz do reposit√≥rio 'regog-txt-img', foi crido o diret√≥rio 'inputs'  

~~~bash
$ mkdir inputs
~~~  

No GitHub foi criado o diret√≥rio 'inputs' no reposit√≥rio recog-txt-img

> Comandos/configura√ß√µes:  
> 
> - Bot√£o: "Add File".  
> - Op√ß√£o: + Create new file.  
> - Preenchi: inputs/test.md  
> - Op√ß√£o: Commit changes.  
> - Dentro do diret√≥rio 'inputs': "Add File".  
> - Op√ß√£o: Upload files 
> - Cliquei em "Choose your files".  
> - Carregou o conjunto de imagens.  
>

Foram salvas as imagens, utilizadas observando a codifica√ß√£o dos nomes para manter a ordem em que foram testadas, conforme os arquivos sugeridos na documenta√ß√£o, em quatro grupos: detect-faces-store-camera; exm-ocr-images; image-analysis-store-camera.  

>[!NOTE]
>
> Os arquivos de imagens foram baixados, respectivamente, nas etapas:  
>   - 4.2.1. (https://aka.ms/mslearn-detect-faces), para o arquivo 'detect-faces.zip';  
>   - 4.2.2. ( https://aka.ms/mslearn-ocr-images), para o arquivo 'ocr-images.zip'; e,   
>   - 4.2.3. (https://aka.ms/mslearn-ocr-images), para o arquivo 'ocr-images.zip'.  
>
-------

## 3. Criar uma pasta chamado 'output' e salve os resultados de reconhecimento de texto nessas imagens  

Na maquina local, na raiz do reposit√≥rio 'regog-txt-img', foi crido o diret√≥rio 'output'  

~~~bash
$ mkdir output
~~~  

No GitHub foi criado o diret√≥rio 'output' no reposit√≥rio recog-txt-img

> Comandos/configura√ß√µes:  
> 
> - Bot√£o: "Add File".  
> - Op√ß√£o: + Create new file.  
> - Preenchi: output/test.md  
> - Op√ß√£o: Commit changes.  
> - Dentro do diret√≥rio 'inputs': "Add File".  
> - Op√ß√£o: Upload files 
> - Cliquei em "Choose your files".  
> - Carregou o conjunto de imagens.
>

Foram salvas as imagens, utilizadas observando a codifica√ß√£o dos nomes para manter a ordem em que foram testadas, em quatro grupos: detect-faces-output-store-camera; exm-ocr-output-images; image-analysis-output-store-camera.  

>[!NOTE]
>
> Os arquivos de imagens foram gerados nos testes, respectivamente, nas etapas:  
>   - 4.2.1. Detect faces, passo 7;  
>   - 4.2.2. Read text, passo 6; e,   
>   - 4.2.3. Analyze images, passo 6.  
>

-------

## 4. Criar um arquivo readme.md, incluir Prints e descri√ß√£o do processo, Insights e Possibilidades aprendidas  

-------

### 4.1. Criar um arquivo readme.md  

No GitHub na raiz do reposit√≥rio 'regog-txt-img', foi crido o arquivo 'readme.md'.

> Comandos/configura√ß√µes:  
>  
> - Bot√£o: "Add File".  
> - Op√ß√£o: + Create new file.  
> - Preenchi: readme.md  
> - Op√ß√£o: Commit changes.  
>

Ap√≥s a cria√ß√£o do arquivo, no diret√≥rio local foi feito o git pull do reposit√≥rio.  
O arquivo foi editado no editor do GitHub e com o aux√≠lio do VSCode no diret√≥rio local.  

-------

### 4.2. Prints e descri√ß√£o do processo  

Foram abordados tr√™s processos de identifica√ß√£o no Vision Studio: Detect faces; Read text; e, Analyze images.  

Nos tr√™s casos √© necess√°rio criar um recurso Azure AI services, na pr√≥pria inscri√ß√£o Azure.  

*Configurando para o Visio Studio*:
>
>- 1. Entrar no portal Azure (https://portal.azure.com).  
>- 2. Clicar no bot√£o ÔºãCreate a resource e encnotrar o Azure AI services. Selecionei "criar um plano Azure AI services".  
>     >> Na pagina para criar o recurso Azure AI services, configurei os seguintes itens:  
>     >> - Subscription: Azure subscription 1.  
>     >> - Resource group: LabVision.  
>     >> - Region: East US.  
>     >> - Name: DioFaceLab.  
>     >> - Pricing tier: Standard S0.  
>     >> - Selecinei o check box: "I acknowledge that I have read and understood all the terms below.  
>- 3. Selecionei Review + create then Create e aguardei a implanta√ß√£o se completar.

Na p√°gina "Select a resource to work with", passando o cursor do mouse sobre o recurso criado na lista, marcar o check box √† esquerda do nome do recurso, depois clicar no bot√£o "Select as default resource".  
Com isso a configura√ß√£o b√°sica do Visioon Studio est√° pronta e pode-se trabalhar com as ferramentas de identifica√ß√£o dispon√≠veis.

#### *4.2.1. Detect faces*  

Configura√ß√£o do Detect faces no Vision Studio:  

>- 1. No navegador, ir at√© o Vision Studio (https://portal.vision.cognitive.azure.com).  
>- 2. Na p√°gina "Getting started with Vision", selecinar a aba "Face" e o card "Detect Faces".  
>- 3. Marcar o check box "Try It Out subheading, acknowledge the resource usage policy".  
>- 4. Selecionar as images de exemplo e observar as informa√ß√µes retornadas.  
>- 5. Selecionar imagens em (https://aka.ms/mslearn-detect-faces) para baixar o arquivo "detect-faces.zip". Abrir folder no computador.  
>- 6. Localizar e subir o arquivo nameado 'store-camera-1.jpg'que cont√©m a seguinte imagem:  

<img src="https://github.com/z3mafra/recog-txt-img/blob/main/inputs/detect-faces-store-camera-1.jpg" width="50%">

>- 7. Observe e revise os detalhes de detec√ß√£o de rosto retornados, conforme mostrado aqui:  

<img src="https://github.com/z3mafra/recog-txt-img/blob/main/output/detect-faces-output-store-camera-1.jpg" width="50%">
  
#### *4.2.2. Read text*  

Configura√ß√£o para extrir texto de imagens no Vision Studio:  

>- 1. No navegador, ir at√© o Vision Studio (https://portal.vision.cognitive.azure.com).  
>- 2. Na p√°gina "Getting started with Vision", selecinar a aba "Optical character recognition‚Äù, e o card com o t√≠tulo "Extract text from images‚Äù.
>- 3. Marcar o check box "Try It Out subheading, acknowledge the resource usage policy".  
>- 4. Selecionar imagens em (https://aka.ms/mslearn-ocr-images) para baixar o arquivo "ocr-images.zip". Abrir folder no computador.  
>- 5. Localizar e subir o arquivo nameado 'exm-ocr-images-advert.jpg', que cont√©m a seguinte imagem:  

<img src="https://github.com/z3mafra/recog-txt-img/blob/main/inputs/exm-ocr-images-advert.jpg" width="50%">

>- 6. Observe a informa√ß√£o que retorna da an√°lise. Na imagem, a localiza√ß√£o do texto √© indicada por uma caixa delimitadora, conforme mostrado aqui:  

<img src="https://github.com/z3mafra/recog-txt-img/blob/main/output/exm-ocr-output-images-advert.jpg" width="50%">

-------
 
#### *4.2.3. Analyze images*  

Vejamos a funcionalidade de gerar legendas para uma imagem, do Azure AI Vision.  
As legendas das imagens est√£o dispon√≠veis por meio dos recursos Caption e Dense Captions.  

>- 1. Em um navegador da web, navegue at√© Vision Studio (https://portal.vision.cognitive.azure.com).  
>- 2. Na p√°gina inicial Getting started with Vision, selecione a guia Image analysis e, em seguida, selecione o bloco Add captions to images. 
>- 3. No subt√≠tulo "Try It Out", ler o termo e marcar o check box ‚Äúacknowledge the resource usage policy‚Äù.
>- 4. Selecionar imagens em (https://aka.ms/mslearn-images-for-analysis) para baixar o arquivo "image-analysis.zip". Abrir folder no computador.  
>- 5. Localizar e subir o arquivo nameado 'image-analysis-store-camera-4.jpg'; que cont√©m a seguinte imagem:  

<img src="https://github.com/z3mafra/recog-txt-img/blob/main/inputs/image-analysis-store-camera-4.jpg" width="50%">

>- 6. Observe o texto da legenda gerada, vis√≠vel no painel Atributos detectados √† direita da imagem. A funcionalidade Caption fornece uma frase √∫nica e leg√≠vel que descreve o conte√∫do da imagem, conforme mostrado aqui:  

<img src="https://github.com/z3mafra/recog-txt-img/blob/main/output/image-analysis-output-store-camera-4.jpg" width="50%">  
  
-------

### 4.3. Insights e Possibilidades aprendidas  

S√£o muitas as ideias e aplica√ß√µes poss√≠veis quando se pensa nas possibilidades aprendidas durante conte√∫do deste desafio. Seguem alguns insights e possibilidades que podem ser desenvolvidos em aplica√ß√µes pr√°ticas com esses tr√™s recursos.  

**Detect Faces**: Este recurso pode ser utilizado em sistemas de seguran√ßa para identificar pessoas em tempo real em locais p√∫blicos ou privados, como aeroportos ou pr√©dios corporativos. Tamb√©m pode ser empregado em aplicativos de organiza√ß√£o de fotos, automatizando o processo de marca√ß√£o de pessoas. Al√©m disso, em aplica√ß√µes de entretenimento, como filtros de redes sociais, pode proporcionar uma experi√™ncia interativa aos usu√°rios.[[1](https://learn.microsoft.com/pt-br/visualstudio/ide/navigating-code?view=vs-2022)]  
   
Read Text: Essa funcionalidade √© √∫til para aplicativos de acessibilidade, convertendo texto em imagens em texto leg√≠vel por m√°quina para pessoas com defici√™ncia visual. Em ambientes empresariais, pode ser utilizado para automatizar a extra√ß√£o de informa√ß√µes de documentos, como faturas e contratos. Al√©m disso, em aplicativos de tradu√ß√£o instant√¢nea, pode ajudar os usu√°rios a entenderem conte√∫dos em diferentes idiomas.[[2](https://azure.microsoft.com/pt-br/)]  

Analyze Images: Esse recurso permite extrair insights valiosos de imagens. Em aplica√ß√µes de sa√∫de, pode ser utilizado para analisar imagens m√©dicas, auxiliando m√©dicos no diagn√≥stico de doen√ßas. Em com√©rcio eletr√¥nico, pode ser usado para recomendar produtos com base nas prefer√™ncias do usu√°rio, analisando suas intera√ß√µes visuais. Al√©m disso, em aplicativos de seguran√ßa, pode identificar objetos perigosos em imagens de vigil√¢ncia.[[3](https://medium.com/cwi-software/reconhecimento-facial-com-python-b2d0981a1aaa)]    

üåê Sources  
[[1] learn.microsoft.com - Op√ß√µes de revis√£o para navegar pelo c√≥digo no editor](https://learn.microsoft.com/pt-br/visualstudio/ide/navigating-code?view=vs-2022)  
[[2] azure.microsoft.com - Microsoft Azure: Servi√ßos de computa√ß√£o em nuvem](https://azure.microsoft.com/pt-br/)  
[[3] medium.com - Reconhecimento Facial com Python](https://medium.com/cwi-software/reconhecimento-facial-com-python-b2d0981a1aaa)  

-------

## 5. Compartilhar o link do reposit√≥rio atrav√©s do bot√£o 'entregar projeto'  

Antes de finalizar o desafio, uma provid√™ncia importate √© limpar (Clean up) o Visio Studio, deletando os recrusos para n√£o gerar custos desnecess√°rios.

### **Clean up**  
Como √© recomendado na document√ß√£o, sen√£o se pretende fazer mais exerc√≠cios, excluir todos os recursos que n√£o precisa mais. Isso evita acumular custos desnecess√°rios.  

>    1. Abra o portal do Azure (<https://portal.azure.com/>) e selecione o grupo de recursos que cont√©m o recurso que voc√™ criou.  
>    2. Selecione o recurso e selecione Excluir e depois Sim para confirmar. O recurso √© ent√£o exclu√≠do.
>
>>  - **Observa√ß√£o:** Uma curiosidade que, nesta etapa, a plataforma informou que o consumo de recursos na modalidade de acesso gratuito, foi de R$ 0,79. Restando ainda um cr√©dito de R$ 988,18.
 
### **Postar link do reposit√≥rio**

Como √© solicitado no enunciado do desafio, o link do GitHub deve ser compartilhado na plataforma da DIO. Para isso, segui os seguintes passos:
>
>>    1. Abra o portal da DIO (<https://www.dio.me/>), com as credenciais e selecione o [Bootcamp Microsoft AZure AI Fundamentals](https://web.dio.me/track/microsoft-azure-ai-fundamentals).
>    2. Entra na Atividade Desafio de projeto: "Reconhecimento Facial e transforma√ß√£o de imagens em Dados no Azure ML"
>    3. Clica no bot√£o "ENTREGAR PROJETO" 
>    4. Cola o link do projeto na caixa de texto "Reposit√≥rio do Projeto"; Cola a descri√ß√£o do reposit√≥rio; Ler e marcar o Check box "Termos de uso", concordando com os termos o recurso; e,
>    5. Selecione Entregar. O Desafio √© ent√£o entregue.
>

-------

-------
